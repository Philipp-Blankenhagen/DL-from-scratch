{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4930b-2ca2-4582-a561-b6c2659522d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0abdc1bb-01e2-464d-bee9-809db759593e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773a326e-0567-49cb-977d-236415ab070a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545508d-f3de-4755-b41c-81f6ace24452",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b9b9429-0e92-4230-b1a8-f6e15b54c051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the dataset\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False)\n",
    "\n",
    "X = trainset.data\n",
    "y = trainset.targets\n",
    "X = X.type(torch.float)\n",
    "X = (X/255)\n",
    "\n",
    "X_test = testset.data\n",
    "y_test = testset.targets\n",
    "X_test = X_test.type(torch.float)\n",
    "X_test = (X_test/255)\n",
    "\n",
    "\n",
    "# Preprocessing/Transforming\n",
    "# Define a series of transformations\n",
    "transform = transforms.Compose([\n",
    "    #transforms.RandomRotation(20),\n",
    "    transforms.Lambda(lambda x: x.view(x.size(0), -1)) # Flatten the tensor\n",
    "])\n",
    "\n",
    "X_t = transform(X)\n",
    "y_t = y\n",
    "\n",
    "\n",
    "X_test = transform(X_test)\n",
    "X_test_gpu = X_test.to(device)\n",
    "y_test_gpu = y_test.to(device)\n",
    "\n",
    "\n",
    "X_gpu = X_t.to(device)\n",
    "y_gpu = y.to(device)\n",
    "# Convert to Dataset and put in a DataLoader\n",
    "tensor_dataset = TensorDataset(X_gpu, y_gpu)\n",
    "dataloader = DataLoader(tensor_dataset,batch_size=100,shuffle = True)\n",
    "\n",
    "\n",
    "tensor_dataset_test = TensorDataset(X_test, y_test)\n",
    "dataloader_test = DataLoader(tensor_dataset_test,batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5919e36a-cff4-4401-be3d-9e540e7a34f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model_linear(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = torch.nn.Sequential(\n",
    "            torch.nn.Linear(784, 3000,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(3000, 3000,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(3000, 1000,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1000, 500,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(500,10,bias=True),\n",
    "            torch.nn.Softmax(dim =1)\n",
    "        )\n",
    "\n",
    "    def forward(self,X):\n",
    "        y_pred = self.main(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def predict(self,X):\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.main(X)\n",
    "            y_class = torch.argmax(y_pred,dim=1)\n",
    "        return y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71c6ceab-88b4-456d-9630-10bf2615569d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate your model and transfer it to GPU (if available)\n",
    "model = model_linear().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d8fc62a-125b-4da9-a138-6358af0c51d6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0  Training Accuracy: 0.09000000357627869\n",
      "Testing Accuracy: 0.08900000154972076\n",
      "Batch: 1  Training Accuracy: 0.11999999731779099\n",
      "Testing Accuracy: 0.10400000214576721\n",
      "Batch: 2  Training Accuracy: 0.15000000596046448\n",
      "Testing Accuracy: 0.11299999803304672\n",
      "Batch: 3  Training Accuracy: 0.12999999523162842\n",
      "Testing Accuracy: 0.10899999737739563\n",
      "Batch: 4  Training Accuracy: 0.10999999940395355\n",
      "Testing Accuracy: 0.12700000405311584\n",
      "Batch: 5  Training Accuracy: 0.10999999940395355\n",
      "Testing Accuracy: 0.09600000083446503\n",
      "Batch: 6  Training Accuracy: 0.1599999964237213\n",
      "Testing Accuracy: 0.08699999749660492\n",
      "Batch: 7  Training Accuracy: 0.11999999731779099\n",
      "Testing Accuracy: 0.08699999749660492\n",
      "Batch: 8  Training Accuracy: 0.10000000149011612\n",
      "Testing Accuracy: 0.08699999749660492\n",
      "Batch: 9  Training Accuracy: 0.12999999523162842\n",
      "Testing Accuracy: 0.08699999749660492\n",
      "Batch: 10  Training Accuracy: 0.07999999821186066\n",
      "Testing Accuracy: 0.08699999749660492\n",
      "Batch: 11  Training Accuracy: 0.11999999731779099\n",
      "Testing Accuracy: 0.08699999749660492\n",
      "Batch: 12  Training Accuracy: 0.07000000029802322\n",
      "Testing Accuracy: 0.08699999749660492\n",
      "Batch: 13  Training Accuracy: 0.03999999910593033\n",
      "Testing Accuracy: 0.09000000357627869\n",
      "Batch: 14  Training Accuracy: 0.09000000357627869\n",
      "Testing Accuracy: 0.09200000017881393\n",
      "Batch: 15  Training Accuracy: 0.1599999964237213\n",
      "Testing Accuracy: 0.09200000017881393\n",
      "Batch: 16  Training Accuracy: 0.07999999821186066\n",
      "Testing Accuracy: 0.14100000262260437\n",
      "Batch: 17  Training Accuracy: 0.25\n",
      "Testing Accuracy: 0.13600000739097595\n",
      "Batch: 18  Training Accuracy: 0.10000000149011612\n",
      "Testing Accuracy: 0.15399999916553497\n",
      "Batch: 19  Training Accuracy: 0.1899999976158142\n",
      "Testing Accuracy: 0.08900000154972076\n",
      "Batch: 20  Training Accuracy: 0.10000000149011612\n",
      "Testing Accuracy: 0.1120000034570694\n",
      "Batch: 21  Training Accuracy: 0.12999999523162842\n",
      "Testing Accuracy: 0.2150000035762787\n",
      "Batch: 22  Training Accuracy: 0.25999999046325684\n",
      "Testing Accuracy: 0.20499999821186066\n",
      "Batch: 23  Training Accuracy: 0.18000000715255737\n",
      "Testing Accuracy: 0.20900000631809235\n",
      "Batch: 24  Training Accuracy: 0.10000000149011612\n",
      "Testing Accuracy: 0.22300000488758087\n",
      "Batch: 25  Training Accuracy: 0.1899999976158142\n",
      "Testing Accuracy: 0.2460000067949295\n",
      "Batch: 26  Training Accuracy: 0.1599999964237213\n",
      "Testing Accuracy: 0.24799999594688416\n",
      "Batch: 27  Training Accuracy: 0.2199999988079071\n",
      "Testing Accuracy: 0.2529999911785126\n",
      "Batch: 28  Training Accuracy: 0.2199999988079071\n",
      "Testing Accuracy: 0.23499999940395355\n",
      "Batch: 29  Training Accuracy: 0.36000001430511475\n",
      "Testing Accuracy: 0.25099998712539673\n",
      "Batch: 30  Training Accuracy: 0.3100000023841858\n",
      "Testing Accuracy: 0.25699999928474426\n",
      "Batch: 31  Training Accuracy: 0.27000001072883606\n",
      "Testing Accuracy: 0.25999999046325684\n",
      "Batch: 32  Training Accuracy: 0.25\n",
      "Testing Accuracy: 0.2590000033378601\n",
      "Batch: 33  Training Accuracy: 0.28999999165534973\n",
      "Testing Accuracy: 0.2619999945163727\n",
      "Batch: 34  Training Accuracy: 0.23000000417232513\n",
      "Testing Accuracy: 0.25\n",
      "Batch: 35  Training Accuracy: 0.25\n",
      "Testing Accuracy: 0.26600000262260437\n",
      "Batch: 36  Training Accuracy: 0.3100000023841858\n",
      "Testing Accuracy: 0.2750000059604645\n",
      "Batch: 37  Training Accuracy: 0.25\n",
      "Testing Accuracy: 0.2939999997615814\n",
      "Batch: 38  Training Accuracy: 0.30000001192092896\n",
      "Testing Accuracy: 0.28299999237060547\n",
      "Batch: 39  Training Accuracy: 0.23999999463558197\n",
      "Testing Accuracy: 0.2930000126361847\n",
      "Batch: 40  Training Accuracy: 0.3499999940395355\n",
      "Testing Accuracy: 0.24699999392032623\n",
      "Batch: 41  Training Accuracy: 0.28999999165534973\n",
      "Testing Accuracy: 0.2370000034570694\n",
      "Batch: 42  Training Accuracy: 0.20000000298023224\n",
      "Testing Accuracy: 0.24199999868869781\n",
      "Batch: 43  Training Accuracy: 0.1599999964237213\n",
      "Testing Accuracy: 0.28600001335144043\n",
      "Batch: 44  Training Accuracy: 0.2800000011920929\n",
      "Testing Accuracy: 0.30000001192092896\n",
      "Batch: 45  Training Accuracy: 0.25999999046325684\n",
      "Testing Accuracy: 0.33399999141693115\n",
      "Batch: 46  Training Accuracy: 0.3199999928474426\n",
      "Testing Accuracy: 0.38199999928474426\n",
      "Batch: 47  Training Accuracy: 0.3199999928474426\n",
      "Testing Accuracy: 0.36000001430511475\n",
      "Batch: 48  Training Accuracy: 0.30000001192092896\n",
      "Testing Accuracy: 0.4569999873638153\n",
      "Batch: 49  Training Accuracy: 0.4399999976158142\n",
      "Testing Accuracy: 0.4359999895095825\n",
      "Batch: 50  Training Accuracy: 0.5699999928474426\n",
      "Testing Accuracy: 0.39500001072883606\n",
      "Batch: 51  Training Accuracy: 0.3400000035762787\n",
      "Testing Accuracy: 0.35600000619888306\n",
      "Batch: 52  Training Accuracy: 0.30000001192092896\n",
      "Testing Accuracy: 0.3700000047683716\n",
      "Batch: 53  Training Accuracy: 0.3499999940395355\n",
      "Testing Accuracy: 0.41600000858306885\n",
      "Batch: 54  Training Accuracy: 0.4399999976158142\n",
      "Testing Accuracy: 0.43299999833106995\n",
      "Batch: 55  Training Accuracy: 0.4000000059604645\n",
      "Testing Accuracy: 0.4620000123977661\n",
      "Batch: 56  Training Accuracy: 0.4300000071525574\n",
      "Testing Accuracy: 0.41200000047683716\n",
      "Batch: 57  Training Accuracy: 0.49000000953674316\n",
      "Testing Accuracy: 0.33899998664855957\n",
      "Batch: 58  Training Accuracy: 0.2800000011920929\n",
      "Testing Accuracy: 0.3869999945163727\n",
      "Batch: 59  Training Accuracy: 0.38999998569488525\n",
      "Testing Accuracy: 0.367000013589859\n",
      "Batch: 60  Training Accuracy: 0.30000001192092896\n",
      "Testing Accuracy: 0.33500000834465027\n",
      "Batch: 61  Training Accuracy: 0.3499999940395355\n",
      "Testing Accuracy: 0.31700000166893005\n",
      "Batch: 62  Training Accuracy: 0.33000001311302185\n",
      "Testing Accuracy: 0.3019999861717224\n",
      "Batch: 63  Training Accuracy: 0.2800000011920929\n",
      "Testing Accuracy: 0.32499998807907104\n",
      "Batch: 64  Training Accuracy: 0.30000001192092896\n",
      "Testing Accuracy: 0.33500000834465027\n",
      "Batch: 65  Training Accuracy: 0.3100000023841858\n",
      "Testing Accuracy: 0.33000001311302185\n",
      "Batch: 66  Training Accuracy: 0.3799999952316284\n",
      "Testing Accuracy: 0.30399999022483826\n",
      "Batch: 67  Training Accuracy: 0.25\n",
      "Testing Accuracy: 0.27399998903274536\n",
      "Batch: 68  Training Accuracy: 0.3499999940395355\n",
      "Testing Accuracy: 0.24300000071525574\n",
      "Batch: 69  Training Accuracy: 0.2800000011920929\n",
      "Testing Accuracy: 0.22499999403953552\n",
      "Batch: 70  Training Accuracy: 0.17000000178813934\n",
      "Testing Accuracy: 0.2370000034570694\n",
      "Batch: 71  Training Accuracy: 0.20000000298023224\n",
      "Testing Accuracy: 0.24400000274181366\n",
      "Batch: 72  Training Accuracy: 0.1599999964237213\n",
      "Testing Accuracy: 0.21299999952316284\n",
      "Batch: 73  Training Accuracy: 0.20999999344348907\n",
      "Testing Accuracy: 0.210999995470047\n",
      "Batch: 74  Training Accuracy: 0.1899999976158142\n",
      "Testing Accuracy: 0.20800000429153442\n",
      "Batch: 75  Training Accuracy: 0.20999999344348907\n",
      "Testing Accuracy: 0.1889999955892563\n",
      "Batch: 76  Training Accuracy: 0.2199999988079071\n",
      "Testing Accuracy: 0.17299999296665192\n",
      "Batch: 77  Training Accuracy: 0.12999999523162842\n",
      "Testing Accuracy: 0.19599999487400055\n",
      "Batch: 78  Training Accuracy: 0.2199999988079071\n",
      "Testing Accuracy: 0.19099999964237213\n",
      "Batch: 79  Training Accuracy: 0.18000000715255737\n",
      "Testing Accuracy: 0.21199999749660492\n",
      "Batch: 80  Training Accuracy: 0.23000000417232513\n",
      "Testing Accuracy: 0.21400000154972076\n",
      "Batch: 81  Training Accuracy: 0.20999999344348907\n",
      "Testing Accuracy: 0.2529999911785126\n",
      "Batch: 82  Training Accuracy: 0.3499999940395355\n",
      "Testing Accuracy: 0.21400000154972076\n",
      "Batch: 83  Training Accuracy: 0.09000000357627869\n",
      "Testing Accuracy: 0.25999999046325684\n",
      "Batch: 84  Training Accuracy: 0.28999999165534973\n",
      "Testing Accuracy: 0.2590000033378601\n",
      "Batch: 85  Training Accuracy: 0.3700000047683716\n",
      "Testing Accuracy: 0.2329999953508377\n",
      "Batch: 86  Training Accuracy: 0.20000000298023224\n",
      "Testing Accuracy: 0.21199999749660492\n",
      "Batch: 87  Training Accuracy: 0.12999999523162842\n",
      "Testing Accuracy: 0.25699999928474426\n",
      "Batch: 88  Training Accuracy: 0.28999999165534973\n",
      "Testing Accuracy: 0.28299999237060547\n",
      "Batch: 89  Training Accuracy: 0.3100000023841858\n",
      "Testing Accuracy: 0.2630000114440918\n",
      "Batch: 90  Training Accuracy: 0.3100000023841858\n",
      "Testing Accuracy: 0.23499999940395355\n",
      "Batch: 91  Training Accuracy: 0.33000001311302185\n",
      "Testing Accuracy: 0.23199999332427979\n",
      "Batch: 92  Training Accuracy: 0.2199999988079071\n",
      "Testing Accuracy: 0.2240000069141388\n",
      "Batch: 93  Training Accuracy: 0.20999999344348907\n",
      "Testing Accuracy: 0.2879999876022339\n",
      "Batch: 94  Training Accuracy: 0.25\n",
      "Testing Accuracy: 0.2540000081062317\n",
      "Batch: 95  Training Accuracy: 0.2199999988079071\n",
      "Testing Accuracy: 0.33799999952316284\n",
      "Batch: 96  Training Accuracy: 0.38999998569488525\n",
      "Testing Accuracy: 0.3440000116825104\n",
      "Batch: 97  Training Accuracy: 0.36000001430511475\n",
      "Testing Accuracy: 0.25200000405311584\n",
      "Batch: 98  Training Accuracy: 0.25999999046325684\n",
      "Testing Accuracy: 0.19499999284744263\n",
      "Batch: 99  Training Accuracy: 0.20000000298023224\n",
      "Testing Accuracy: 0.3630000054836273\n",
      "Batch: 100  Training Accuracy: 0.38999998569488525\n",
      "Testing Accuracy: 0.28700000047683716\n",
      "Batch: 101  Training Accuracy: 0.33000001311302185\n",
      "Testing Accuracy: 0.35100001096725464\n",
      "Batch: 102  Training Accuracy: 0.38999998569488525\n",
      "Testing Accuracy: 0.28999999165534973\n",
      "Batch: 103  Training Accuracy: 0.27000001072883606\n",
      "Testing Accuracy: 0.2849999964237213\n",
      "Batch: 104  Training Accuracy: 0.27000001072883606\n",
      "Testing Accuracy: 0.3240000009536743\n",
      "Batch: 105  Training Accuracy: 0.3499999940395355\n",
      "Testing Accuracy: 0.34200000762939453\n",
      "Batch: 106  Training Accuracy: 0.28999999165534973\n",
      "Testing Accuracy: 0.375\n",
      "Batch: 107  Training Accuracy: 0.49000000953674316\n",
      "Testing Accuracy: 0.3779999911785126\n",
      "Batch: 108  Training Accuracy: 0.3400000035762787\n",
      "Testing Accuracy: 0.40799999237060547\n",
      "Batch: 109  Training Accuracy: 0.3799999952316284\n",
      "Testing Accuracy: 0.3569999933242798\n",
      "Batch: 110  Training Accuracy: 0.33000001311302185\n",
      "Testing Accuracy: 0.4259999990463257\n",
      "Batch: 111  Training Accuracy: 0.4000000059604645\n",
      "Testing Accuracy: 0.42500001192092896\n",
      "Batch: 112  Training Accuracy: 0.47999998927116394\n",
      "Testing Accuracy: 0.328000009059906\n",
      "Batch: 113  Training Accuracy: 0.28999999165534973\n",
      "Testing Accuracy: 0.39500001072883606\n",
      "Batch: 114  Training Accuracy: 0.4300000071525574\n",
      "Testing Accuracy: 0.44200000166893005\n",
      "Batch: 115  Training Accuracy: 0.5\n",
      "Testing Accuracy: 0.3709999918937683\n",
      "Batch: 116  Training Accuracy: 0.4099999964237213\n",
      "Testing Accuracy: 0.38100001215934753\n",
      "Batch: 117  Training Accuracy: 0.4000000059604645\n",
      "Testing Accuracy: 0.4180000126361847\n",
      "Batch: 118  Training Accuracy: 0.38999998569488525\n",
      "Testing Accuracy: 0.43799999356269836\n",
      "Batch: 119  Training Accuracy: 0.4399999976158142\n",
      "Testing Accuracy: 0.4950000047683716\n",
      "Batch: 120  Training Accuracy: 0.5099999904632568\n",
      "Testing Accuracy: 0.492000013589859\n",
      "Batch: 121  Training Accuracy: 0.5400000214576721\n",
      "Testing Accuracy: 0.4620000123977661\n",
      "Batch: 122  Training Accuracy: 0.5\n",
      "Testing Accuracy: 0.3970000147819519\n",
      "Batch: 123  Training Accuracy: 0.4300000071525574\n",
      "Testing Accuracy: 0.515999972820282\n",
      "Batch: 124  Training Accuracy: 0.49000000953674316\n",
      "Testing Accuracy: 0.5320000052452087\n",
      "Batch: 125  Training Accuracy: 0.5299999713897705\n",
      "Testing Accuracy: 0.5619999766349792\n",
      "Batch: 126  Training Accuracy: 0.6000000238418579\n",
      "Testing Accuracy: 0.6309999823570251\n",
      "Batch: 127  Training Accuracy: 0.5199999809265137\n",
      "Testing Accuracy: 0.5139999985694885\n",
      "Batch: 128  Training Accuracy: 0.47999998927116394\n",
      "Testing Accuracy: 0.5350000262260437\n",
      "Batch: 129  Training Accuracy: 0.5099999904632568\n",
      "Testing Accuracy: 0.4480000138282776\n",
      "Batch: 130  Training Accuracy: 0.41999998688697815\n",
      "Testing Accuracy: 0.5210000276565552\n",
      "Batch: 131  Training Accuracy: 0.47999998927116394\n",
      "Testing Accuracy: 0.4970000088214874\n",
      "Batch: 132  Training Accuracy: 0.46000000834465027\n",
      "Testing Accuracy: 0.49799999594688416\n",
      "Batch: 133  Training Accuracy: 0.550000011920929\n",
      "Testing Accuracy: 0.4359999895095825\n",
      "Batch: 134  Training Accuracy: 0.49000000953674316\n",
      "Testing Accuracy: 0.47099998593330383\n",
      "Batch: 135  Training Accuracy: 0.5299999713897705\n",
      "Testing Accuracy: 0.5440000295639038\n",
      "Batch: 136  Training Accuracy: 0.5699999928474426\n",
      "Testing Accuracy: 0.48399999737739563\n",
      "Batch: 137  Training Accuracy: 0.47999998927116394\n",
      "Testing Accuracy: 0.492000013589859\n",
      "Batch: 138  Training Accuracy: 0.550000011920929\n",
      "Testing Accuracy: 0.6000000238418579\n",
      "Batch: 139  Training Accuracy: 0.6299999952316284\n",
      "Testing Accuracy: 0.5210000276565552\n",
      "Batch: 140  Training Accuracy: 0.47999998927116394\n",
      "Testing Accuracy: 0.5059999823570251\n",
      "Batch: 141  Training Accuracy: 0.47999998927116394\n",
      "Testing Accuracy: 0.5709999799728394\n",
      "Batch: 142  Training Accuracy: 0.5899999737739563\n",
      "Testing Accuracy: 0.5210000276565552\n",
      "Batch: 143  Training Accuracy: 0.5\n",
      "Testing Accuracy: 0.5350000262260437\n",
      "Batch: 144  Training Accuracy: 0.550000011920929\n",
      "Testing Accuracy: 0.574999988079071\n",
      "Batch: 145  Training Accuracy: 0.6499999761581421\n",
      "Testing Accuracy: 0.6230000257492065\n",
      "Batch: 146  Training Accuracy: 0.6499999761581421\n",
      "Testing Accuracy: 0.625\n",
      "Batch: 147  Training Accuracy: 0.6200000047683716\n",
      "Testing Accuracy: 0.6039999723434448\n",
      "Batch: 148  Training Accuracy: 0.6800000071525574\n",
      "Testing Accuracy: 0.6269999742507935\n",
      "Batch: 149  Training Accuracy: 0.6700000166893005\n",
      "Testing Accuracy: 0.5929999947547913\n",
      "Batch: 150  Training Accuracy: 0.5699999928474426\n",
      "Testing Accuracy: 0.6589999794960022\n",
      "Batch: 151  Training Accuracy: 0.7200000286102295\n",
      "Testing Accuracy: 0.6660000085830688\n",
      "Batch: 152  Training Accuracy: 0.7200000286102295\n",
      "Testing Accuracy: 0.656000018119812\n",
      "Batch: 153  Training Accuracy: 0.6800000071525574\n",
      "Testing Accuracy: 0.6669999957084656\n",
      "Batch: 154  Training Accuracy: 0.7300000190734863\n",
      "Testing Accuracy: 0.6890000104904175\n",
      "Batch: 155  Training Accuracy: 0.6800000071525574\n",
      "Testing Accuracy: 0.6949999928474426\n",
      "Batch: 156  Training Accuracy: 0.6899999976158142\n",
      "Testing Accuracy: 0.6119999885559082\n",
      "Batch: 157  Training Accuracy: 0.550000011920929\n",
      "Testing Accuracy: 0.6209999918937683\n",
      "Batch: 158  Training Accuracy: 0.6200000047683716\n",
      "Testing Accuracy: 0.6899999976158142\n",
      "Batch: 159  Training Accuracy: 0.7200000286102295\n",
      "Testing Accuracy: 0.6800000071525574\n",
      "Batch: 160  Training Accuracy: 0.7400000095367432\n",
      "Testing Accuracy: 0.5820000171661377\n",
      "Batch: 161  Training Accuracy: 0.6299999952316284\n",
      "Testing Accuracy: 0.5879999995231628\n",
      "Batch: 162  Training Accuracy: 0.5199999809265137\n",
      "Testing Accuracy: 0.6439999938011169\n",
      "Batch: 163  Training Accuracy: 0.6000000238418579\n",
      "Testing Accuracy: 0.6069999933242798\n",
      "Batch: 164  Training Accuracy: 0.5699999928474426\n",
      "Testing Accuracy: 0.6019999980926514\n",
      "Batch: 165  Training Accuracy: 0.5299999713897705\n",
      "Testing Accuracy: 0.6909999847412109\n",
      "Batch: 166  Training Accuracy: 0.6700000166893005\n",
      "Testing Accuracy: 0.6510000228881836\n",
      "Batch: 167  Training Accuracy: 0.6499999761581421\n",
      "Testing Accuracy: 0.7099999785423279\n",
      "Batch: 168  Training Accuracy: 0.7300000190734863\n",
      "Testing Accuracy: 0.7149999737739563\n",
      "Batch: 169  Training Accuracy: 0.6600000262260437\n",
      "Testing Accuracy: 0.6840000152587891\n",
      "Batch: 170  Training Accuracy: 0.6499999761581421\n",
      "Testing Accuracy: 0.609000027179718\n",
      "Batch: 171  Training Accuracy: 0.5299999713897705\n",
      "Testing Accuracy: 0.6399999856948853\n",
      "Batch: 172  Training Accuracy: 0.6800000071525574\n",
      "Testing Accuracy: 0.6980000138282776\n",
      "Batch: 173  Training Accuracy: 0.6600000262260437\n",
      "Testing Accuracy: 0.7239999771118164\n",
      "Batch: 174  Training Accuracy: 0.7200000286102295\n",
      "Testing Accuracy: 0.48100000619888306\n",
      "Batch: 175  Training Accuracy: 0.4300000071525574\n",
      "Testing Accuracy: 0.6269999742507935\n",
      "Batch: 176  Training Accuracy: 0.6499999761581421\n",
      "Testing Accuracy: 0.6990000009536743\n",
      "Batch: 177  Training Accuracy: 0.7099999785423279\n",
      "Testing Accuracy: 0.5559999942779541\n",
      "Batch: 178  Training Accuracy: 0.5699999928474426\n",
      "Testing Accuracy: 0.6629999876022339\n",
      "Batch: 179  Training Accuracy: 0.6600000262260437\n",
      "Testing Accuracy: 0.7210000157356262\n",
      "Batch: 180  Training Accuracy: 0.699999988079071\n",
      "Testing Accuracy: 0.7419999837875366\n",
      "Batch: 181  Training Accuracy: 0.7599999904632568\n",
      "Testing Accuracy: 0.7049999833106995\n",
      "Batch: 182  Training Accuracy: 0.75\n",
      "Testing Accuracy: 0.7599999904632568\n",
      "Batch: 183  Training Accuracy: 0.7799999713897705\n",
      "Testing Accuracy: 0.7549999952316284\n",
      "Batch: 184  Training Accuracy: 0.7300000190734863\n",
      "Testing Accuracy: 0.7120000123977661\n",
      "Batch: 185  Training Accuracy: 0.7200000286102295\n",
      "Testing Accuracy: 0.6610000133514404\n",
      "Batch: 186  Training Accuracy: 0.6899999976158142\n",
      "Testing Accuracy: 0.7210000157356262\n",
      "Batch: 187  Training Accuracy: 0.7099999785423279\n",
      "Testing Accuracy: 0.7059999704360962\n",
      "Batch: 188  Training Accuracy: 0.7200000286102295\n",
      "Testing Accuracy: 0.5630000233650208\n",
      "Batch: 189  Training Accuracy: 0.5400000214576721\n",
      "Testing Accuracy: 0.7630000114440918\n",
      "Batch: 190  Training Accuracy: 0.7200000286102295\n",
      "Testing Accuracy: 0.7160000205039978\n",
      "Batch: 191  Training Accuracy: 0.6800000071525574\n",
      "Testing Accuracy: 0.7639999985694885\n",
      "Batch: 192  Training Accuracy: 0.7799999713897705\n",
      "Testing Accuracy: 0.7450000047683716\n",
      "Batch: 193  Training Accuracy: 0.699999988079071\n",
      "Testing Accuracy: 0.7070000171661377\n",
      "Batch: 194  Training Accuracy: 0.6399999856948853\n",
      "Testing Accuracy: 0.6869999766349792\n",
      "Batch: 195  Training Accuracy: 0.6600000262260437\n",
      "Testing Accuracy: 0.7910000085830688\n",
      "Batch: 196  Training Accuracy: 0.7300000190734863\n",
      "Testing Accuracy: 0.7760000228881836\n",
      "Batch: 197  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.7419999837875366\n",
      "Batch: 198  Training Accuracy: 0.7400000095367432\n",
      "Testing Accuracy: 0.7350000143051147\n",
      "Batch: 199  Training Accuracy: 0.7799999713897705\n",
      "Testing Accuracy: 0.6600000262260437\n",
      "Batch: 200  Training Accuracy: 0.6000000238418579\n",
      "Testing Accuracy: 0.734000027179718\n",
      "Batch: 201  Training Accuracy: 0.7099999785423279\n",
      "Testing Accuracy: 0.6859999895095825\n",
      "Batch: 202  Training Accuracy: 0.6299999952316284\n",
      "Testing Accuracy: 0.7680000066757202\n",
      "Batch: 203  Training Accuracy: 0.7599999904632568\n",
      "Testing Accuracy: 0.7860000133514404\n",
      "Batch: 204  Training Accuracy: 0.8100000023841858\n",
      "Testing Accuracy: 0.7179999947547913\n",
      "Batch: 205  Training Accuracy: 0.7099999785423279\n",
      "Testing Accuracy: 0.7940000295639038\n",
      "Batch: 206  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.7400000095367432\n",
      "Batch: 207  Training Accuracy: 0.6800000071525574\n",
      "Testing Accuracy: 0.6420000195503235\n",
      "Batch: 208  Training Accuracy: 0.5899999737739563\n",
      "Testing Accuracy: 0.7350000143051147\n",
      "Batch: 209  Training Accuracy: 0.8199999928474426\n",
      "Testing Accuracy: 0.7889999747276306\n",
      "Batch: 210  Training Accuracy: 0.7200000286102295\n",
      "Testing Accuracy: 0.6930000185966492\n",
      "Batch: 211  Training Accuracy: 0.7099999785423279\n",
      "Testing Accuracy: 0.6520000100135803\n",
      "Batch: 212  Training Accuracy: 0.6700000166893005\n",
      "Testing Accuracy: 0.7459999918937683\n",
      "Batch: 213  Training Accuracy: 0.7400000095367432\n",
      "Testing Accuracy: 0.7710000276565552\n",
      "Batch: 214  Training Accuracy: 0.7400000095367432\n",
      "Testing Accuracy: 0.7960000038146973\n",
      "Batch: 215  Training Accuracy: 0.8100000023841858\n",
      "Testing Accuracy: 0.7630000114440918\n",
      "Batch: 216  Training Accuracy: 0.7900000214576721\n",
      "Testing Accuracy: 0.7549999952316284\n",
      "Batch: 217  Training Accuracy: 0.7799999713897705\n",
      "Testing Accuracy: 0.7490000128746033\n",
      "Batch: 218  Training Accuracy: 0.7699999809265137\n",
      "Testing Accuracy: 0.7490000128746033\n",
      "Batch: 219  Training Accuracy: 0.75\n",
      "Testing Accuracy: 0.7409999966621399\n",
      "Batch: 220  Training Accuracy: 0.7400000095367432\n",
      "Testing Accuracy: 0.671999990940094\n",
      "Batch: 221  Training Accuracy: 0.75\n",
      "Testing Accuracy: 0.7609999775886536\n",
      "Batch: 222  Training Accuracy: 0.7599999904632568\n",
      "Testing Accuracy: 0.7559999823570251\n",
      "Batch: 223  Training Accuracy: 0.7400000095367432\n",
      "Testing Accuracy: 0.7020000219345093\n",
      "Batch: 224  Training Accuracy: 0.6899999976158142\n",
      "Testing Accuracy: 0.7139999866485596\n",
      "Batch: 225  Training Accuracy: 0.7200000286102295\n",
      "Testing Accuracy: 0.8050000071525574\n",
      "Batch: 226  Training Accuracy: 0.7900000214576721\n",
      "Testing Accuracy: 0.7549999952316284\n",
      "Batch: 227  Training Accuracy: 0.75\n",
      "Testing Accuracy: 0.8240000009536743\n",
      "Batch: 228  Training Accuracy: 0.7799999713897705\n",
      "Testing Accuracy: 0.7559999823570251\n",
      "Batch: 229  Training Accuracy: 0.7599999904632568\n",
      "Testing Accuracy: 0.8149999976158142\n",
      "Batch: 230  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8149999976158142\n",
      "Batch: 231  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8479999899864197\n",
      "Batch: 232  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8080000281333923\n",
      "Batch: 233  Training Accuracy: 0.7400000095367432\n",
      "Testing Accuracy: 0.7570000290870667\n",
      "Batch: 234  Training Accuracy: 0.7400000095367432\n",
      "Testing Accuracy: 0.800000011920929\n",
      "Batch: 235  Training Accuracy: 0.8199999928474426\n",
      "Testing Accuracy: 0.7599999904632568\n",
      "Batch: 236  Training Accuracy: 0.75\n",
      "Testing Accuracy: 0.8080000281333923\n",
      "Batch: 237  Training Accuracy: 0.8399999737739563\n",
      "Testing Accuracy: 0.8330000042915344\n",
      "Batch: 238  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.7929999828338623\n",
      "Batch: 239  Training Accuracy: 0.7900000214576721\n",
      "Testing Accuracy: 0.8130000233650208\n",
      "Batch: 240  Training Accuracy: 0.75\n",
      "Testing Accuracy: 0.6589999794960022\n",
      "Batch: 241  Training Accuracy: 0.6600000262260437\n",
      "Testing Accuracy: 0.7429999709129333\n",
      "Batch: 242  Training Accuracy: 0.6700000166893005\n",
      "Testing Accuracy: 0.718999981880188\n",
      "Batch: 243  Training Accuracy: 0.6899999976158142\n",
      "Testing Accuracy: 0.7210000157356262\n",
      "Batch: 244  Training Accuracy: 0.7699999809265137\n",
      "Testing Accuracy: 0.718999981880188\n",
      "Batch: 245  Training Accuracy: 0.7599999904632568\n",
      "Testing Accuracy: 0.7620000243186951\n",
      "Batch: 246  Training Accuracy: 0.8199999928474426\n",
      "Testing Accuracy: 0.8429999947547913\n",
      "Batch: 247  Training Accuracy: 0.8100000023841858\n",
      "Testing Accuracy: 0.8320000171661377\n",
      "Batch: 248  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.7540000081062317\n",
      "Batch: 249  Training Accuracy: 0.6800000071525574\n",
      "Testing Accuracy: 0.6600000262260437\n",
      "Batch: 250  Training Accuracy: 0.6600000262260437\n",
      "Testing Accuracy: 0.7570000290870667\n",
      "Batch: 251  Training Accuracy: 0.7599999904632568\n",
      "Testing Accuracy: 0.8040000200271606\n",
      "Batch: 252  Training Accuracy: 0.7799999713897705\n",
      "Testing Accuracy: 0.7749999761581421\n",
      "Batch: 253  Training Accuracy: 0.800000011920929\n",
      "Testing Accuracy: 0.8320000171661377\n",
      "Batch: 254  Training Accuracy: 0.8199999928474426\n",
      "Testing Accuracy: 0.8410000205039978\n",
      "Batch: 255  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.8180000185966492\n",
      "Batch: 256  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8140000104904175\n",
      "Batch: 257  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8159999847412109\n",
      "Batch: 258  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8489999771118164\n",
      "Batch: 259  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8550000190734863\n",
      "Batch: 260  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.7770000100135803\n",
      "Batch: 261  Training Accuracy: 0.8399999737739563\n",
      "Testing Accuracy: 0.8270000219345093\n",
      "Batch: 262  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.8240000009536743\n",
      "Batch: 263  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.8450000286102295\n",
      "Batch: 264  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.859000027179718\n",
      "Batch: 265  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.8429999947547913\n",
      "Batch: 266  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.8209999799728394\n",
      "Batch: 267  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.8560000061988831\n",
      "Batch: 268  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.843999981880188\n",
      "Batch: 269  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8209999799728394\n",
      "Batch: 270  Training Accuracy: 0.800000011920929\n",
      "Testing Accuracy: 0.7829999923706055\n",
      "Batch: 271  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.8379999995231628\n",
      "Batch: 272  Training Accuracy: 0.800000011920929\n",
      "Testing Accuracy: 0.8550000190734863\n",
      "Batch: 273  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.847000002861023\n",
      "Batch: 274  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8539999723434448\n",
      "Batch: 275  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.8270000219345093\n",
      "Batch: 276  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.8240000009536743\n",
      "Batch: 277  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.765999972820282\n",
      "Batch: 278  Training Accuracy: 0.7799999713897705\n",
      "Testing Accuracy: 0.8029999732971191\n",
      "Batch: 279  Training Accuracy: 0.8100000023841858\n",
      "Testing Accuracy: 0.8109999895095825\n",
      "Batch: 280  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.847000002861023\n",
      "Batch: 281  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.7870000004768372\n",
      "Batch: 282  Training Accuracy: 0.7900000214576721\n",
      "Testing Accuracy: 0.8610000014305115\n",
      "Batch: 283  Training Accuracy: 0.8100000023841858\n",
      "Testing Accuracy: 0.8709999918937683\n",
      "Batch: 284  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8629999756813049\n",
      "Batch: 285  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.7490000128746033\n",
      "Batch: 286  Training Accuracy: 0.8399999737739563\n",
      "Testing Accuracy: 0.8600000143051147\n",
      "Batch: 287  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8640000224113464\n",
      "Batch: 288  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8519999980926514\n",
      "Batch: 289  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8650000095367432\n",
      "Batch: 290  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8629999756813049\n",
      "Batch: 291  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8500000238418579\n",
      "Batch: 292  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8489999771118164\n",
      "Batch: 293  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8769999742507935\n",
      "Batch: 294  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8740000128746033\n",
      "Batch: 295  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8500000238418579\n",
      "Batch: 296  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8880000114440918\n",
      "Batch: 297  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8830000162124634\n",
      "Batch: 298  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8360000252723694\n",
      "Batch: 299  Training Accuracy: 0.800000011920929\n",
      "Testing Accuracy: 0.8769999742507935\n",
      "Batch: 300  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8569999933242798\n",
      "Batch: 301  Training Accuracy: 0.7799999713897705\n",
      "Testing Accuracy: 0.8769999742507935\n",
      "Batch: 302  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8579999804496765\n",
      "Batch: 303  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.8899999856948853\n",
      "Batch: 304  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8809999823570251\n",
      "Batch: 305  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8610000014305115\n",
      "Batch: 306  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8769999742507935\n",
      "Batch: 307  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8370000123977661\n",
      "Batch: 308  Training Accuracy: 0.800000011920929\n",
      "Testing Accuracy: 0.7400000095367432\n",
      "Batch: 309  Training Accuracy: 0.7799999713897705\n",
      "Testing Accuracy: 0.8510000109672546\n",
      "Batch: 310  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8539999723434448\n",
      "Batch: 311  Training Accuracy: 0.8399999737739563\n",
      "Testing Accuracy: 0.8579999804496765\n",
      "Batch: 312  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8690000176429749\n",
      "Batch: 313  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.875\n",
      "Batch: 314  Training Accuracy: 0.8399999737739563\n",
      "Testing Accuracy: 0.8610000014305115\n",
      "Batch: 315  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8769999742507935\n",
      "Batch: 316  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.878000020980835\n",
      "Batch: 317  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.8709999918937683\n",
      "Batch: 318  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8809999823570251\n",
      "Batch: 319  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8709999918937683\n",
      "Batch: 320  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8899999856948853\n",
      "Batch: 321  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.8809999823570251\n",
      "Batch: 322  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8889999985694885\n",
      "Batch: 323  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.890999972820282\n",
      "Batch: 324  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8640000224113464\n",
      "Batch: 325  Training Accuracy: 0.8199999928474426\n",
      "Testing Accuracy: 0.8669999837875366\n",
      "Batch: 326  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8349999785423279\n",
      "Batch: 327  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8849999904632568\n",
      "Batch: 328  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8500000238418579\n",
      "Batch: 329  Training Accuracy: 0.8100000023841858\n",
      "Testing Accuracy: 0.878000020980835\n",
      "Batch: 330  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8569999933242798\n",
      "Batch: 331  Training Accuracy: 0.8199999928474426\n",
      "Testing Accuracy: 0.8410000205039978\n",
      "Batch: 332  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8849999904632568\n",
      "Batch: 333  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8820000290870667\n",
      "Batch: 334  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.8679999709129333\n",
      "Batch: 335  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8320000171661377\n",
      "Batch: 336  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8489999771118164\n",
      "Batch: 337  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8740000128746033\n",
      "Batch: 338  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8759999871253967\n",
      "Batch: 339  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8740000128746033\n",
      "Batch: 340  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.875\n",
      "Batch: 341  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8809999823570251\n",
      "Batch: 342  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8650000095367432\n",
      "Batch: 343  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8730000257492065\n",
      "Batch: 344  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8840000033378601\n",
      "Batch: 345  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8840000033378601\n",
      "Batch: 346  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8619999885559082\n",
      "Batch: 347  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8759999871253967\n",
      "Batch: 348  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8619999885559082\n",
      "Batch: 349  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8460000157356262\n",
      "Batch: 350  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8709999918937683\n",
      "Batch: 351  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.902999997138977\n",
      "Batch: 352  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.8809999823570251\n",
      "Batch: 353  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8830000162124634\n",
      "Batch: 354  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.890999972820282\n",
      "Batch: 355  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8939999938011169\n",
      "Batch: 356  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.8989999890327454\n",
      "Batch: 357  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 358  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 359  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9089999794960022\n",
      "Batch: 360  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8949999809265137\n",
      "Batch: 361  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8989999890327454\n",
      "Batch: 362  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.9039999842643738\n",
      "Batch: 363  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8859999775886536\n",
      "Batch: 364  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9100000262260437\n",
      "Batch: 365  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9010000228881836\n",
      "Batch: 366  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9039999842643738\n",
      "Batch: 367  Training Accuracy: 0.8399999737739563\n",
      "Testing Accuracy: 0.8960000276565552\n",
      "Batch: 368  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9039999842643738\n",
      "Batch: 369  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 370  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9039999842643738\n",
      "Batch: 371  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.8930000066757202\n",
      "Batch: 372  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8880000114440918\n",
      "Batch: 373  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9100000262260437\n",
      "Batch: 374  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 375  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9079999923706055\n",
      "Batch: 376  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9150000214576721\n",
      "Batch: 377  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9100000262260437\n",
      "Batch: 378  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.8960000276565552\n",
      "Batch: 379  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.9020000100135803\n",
      "Batch: 380  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9079999923706055\n",
      "Batch: 381  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.8429999947547913\n",
      "Batch: 382  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8809999823570251\n",
      "Batch: 383  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8930000066757202\n",
      "Batch: 384  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8930000066757202\n",
      "Batch: 385  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 386  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8880000114440918\n",
      "Batch: 387  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8889999985694885\n",
      "Batch: 388  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8870000243186951\n",
      "Batch: 389  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9020000100135803\n",
      "Batch: 390  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9020000100135803\n",
      "Batch: 391  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.8989999890327454\n",
      "Batch: 392  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9010000228881836\n",
      "Batch: 393  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8999999761581421\n",
      "Batch: 394  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8989999890327454\n",
      "Batch: 395  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8889999985694885\n",
      "Batch: 396  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9020000100135803\n",
      "Batch: 397  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 398  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8849999904632568\n",
      "Batch: 399  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9049999713897705\n",
      "Batch: 400  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8960000276565552\n",
      "Batch: 401  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.8759999871253967\n",
      "Batch: 402  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8949999809265137\n",
      "Batch: 403  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 404  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 405  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8849999904632568\n",
      "Batch: 406  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8949999809265137\n",
      "Batch: 407  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9139999747276306\n",
      "Batch: 408  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 409  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9079999923706055\n",
      "Batch: 410  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.906000018119812\n",
      "Batch: 411  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8960000276565552\n",
      "Batch: 412  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 413  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.906000018119812\n",
      "Batch: 414  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 415  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9139999747276306\n",
      "Batch: 416  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 417  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9150000214576721\n",
      "Batch: 418  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8899999856948853\n",
      "Batch: 419  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9100000262260437\n",
      "Batch: 420  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9110000133514404\n",
      "Batch: 421  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8970000147819519\n",
      "Batch: 422  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.9100000262260437\n",
      "Batch: 423  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8980000019073486\n",
      "Batch: 424  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 425  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 426  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9089999794960022\n",
      "Batch: 427  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 428  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.8799999952316284\n",
      "Batch: 429  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 430  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8870000243186951\n",
      "Batch: 431  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.8889999985694885\n",
      "Batch: 432  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 433  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 434  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 435  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9010000228881836\n",
      "Batch: 436  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.8859999775886536\n",
      "Batch: 437  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.8730000257492065\n",
      "Batch: 438  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.8859999775886536\n",
      "Batch: 439  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 440  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 441  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 442  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8939999938011169\n",
      "Batch: 443  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 444  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9139999747276306\n",
      "Batch: 445  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8790000081062317\n",
      "Batch: 446  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.9079999923706055\n",
      "Batch: 447  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 448  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9089999794960022\n",
      "Batch: 449  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9010000228881836\n",
      "Batch: 450  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 451  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 452  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.8949999809265137\n",
      "Batch: 453  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 454  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.906000018119812\n",
      "Batch: 455  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 456  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 457  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 458  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 459  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 460  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9089999794960022\n",
      "Batch: 461  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 462  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8569999933242798\n",
      "Batch: 463  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.890999972820282\n",
      "Batch: 464  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 465  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9110000133514404\n",
      "Batch: 466  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9190000295639038\n",
      "Batch: 467  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8799999952316284\n",
      "Batch: 468  Training Accuracy: 0.8399999737739563\n",
      "Testing Accuracy: 0.8769999742507935\n",
      "Batch: 469  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 470  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 471  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 472  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.8949999809265137\n",
      "Batch: 473  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9190000295639038\n",
      "Batch: 474  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8930000066757202\n",
      "Batch: 475  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 476  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8870000243186951\n",
      "Batch: 477  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9039999842643738\n",
      "Batch: 478  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9079999923706055\n",
      "Batch: 479  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 480  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.902999997138977\n",
      "Batch: 481  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9049999713897705\n",
      "Batch: 482  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 483  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8989999890327454\n",
      "Batch: 484  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9020000100135803\n",
      "Batch: 485  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8830000162124634\n",
      "Batch: 486  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8529999852180481\n",
      "Batch: 487  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 488  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 489  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 490  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9150000214576721\n",
      "Batch: 491  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 492  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 493  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 494  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 495  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 496  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 497  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9089999794960022\n",
      "Batch: 498  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8799999952316284\n",
      "Batch: 499  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 500  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 501  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 502  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 503  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8519999980926514\n",
      "Batch: 504  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8960000276565552\n",
      "Batch: 505  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9139999747276306\n",
      "Batch: 506  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9110000133514404\n",
      "Batch: 507  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 508  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8989999890327454\n",
      "Batch: 509  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.8650000095367432\n",
      "Batch: 510  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 511  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 512  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9190000295639038\n",
      "Batch: 513  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 514  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 515  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 516  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 517  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.8989999890327454\n",
      "Batch: 518  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 519  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 520  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 521  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 522  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 523  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.8999999761581421\n",
      "Batch: 524  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.902999997138977\n",
      "Batch: 525  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8820000290870667\n",
      "Batch: 526  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 527  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 528  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 529  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9039999842643738\n",
      "Batch: 530  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8500000238418579\n",
      "Batch: 531  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8880000114440918\n",
      "Batch: 532  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9079999923706055\n",
      "Batch: 533  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.902999997138977\n",
      "Batch: 534  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 535  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 536  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 537  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 538  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.902999997138977\n",
      "Batch: 539  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 540  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9039999842643738\n",
      "Batch: 541  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 542  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 543  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 544  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 545  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 546  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 547  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 548  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 549  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 550  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.902999997138977\n",
      "Batch: 551  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 552  Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 553  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 554  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 555  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8579999804496765\n",
      "Batch: 556  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 557  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 558  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 559  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 560  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 561  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 562  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 563  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.9089999794960022\n",
      "Batch: 564  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 565  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 566  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 567  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 568  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8849999904632568\n",
      "Batch: 569  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.8949999809265137\n",
      "Batch: 570  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 571  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 572  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 573  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 574  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 575  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 576  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 577  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 578  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 579  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9010000228881836\n",
      "Batch: 580  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 581  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 582  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 583  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 584  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 585  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 586  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9039999842643738\n",
      "Batch: 587  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 588  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 589  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 590  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9150000214576721\n",
      "Batch: 591  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 592  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 593  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.8859999775886536\n",
      "Batch: 594  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 595  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9010000228881836\n",
      "Batch: 596  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 597  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8930000066757202\n",
      "Batch: 598  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9100000262260437\n",
      "Batch: 599  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.906000018119812\n",
      "\n",
      "\n",
      "Epoch 0 \n",
      "\n",
      "\n",
      "Batch: 0  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8510000109672546\n",
      "Batch: 1  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.8889999985694885\n",
      "Batch: 2  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.8830000162124634\n",
      "Batch: 3  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 4  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 5  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.8980000019073486\n",
      "Batch: 6  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 7  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 8  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 9  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 10  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 11  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9190000295639038\n",
      "Batch: 12  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 13  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 14  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 15  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 16  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 17  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9089999794960022\n",
      "Batch: 18  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.9150000214576721\n",
      "Batch: 19  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 20  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 21  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9110000133514404\n",
      "Batch: 22  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9049999713897705\n",
      "Batch: 23  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 24  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 25  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 26  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 27  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 28  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8999999761581421\n",
      "Batch: 29  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 30  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 31  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 32  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 33  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 34  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 35  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 36  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9139999747276306\n",
      "Batch: 37  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9190000295639038\n",
      "Batch: 38  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 39  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 40  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 41  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9160000085830688\n",
      "Batch: 42  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 43  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 44  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9190000295639038\n",
      "Batch: 45  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 46  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 47  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 48  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 49  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 50  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 51  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 52  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 53  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 54  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 55  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 56  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 57  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 58  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 59  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 60  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 61  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9110000133514404\n",
      "Batch: 62  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 63  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 64  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 65  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.921999990940094\n",
      "Batch: 66  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 67  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 68  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 69  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 70  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 71  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 72  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 73  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 74  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 75  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 76  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 77  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 78  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 79  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 80  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 81  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.8830000162124634\n",
      "Batch: 82  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.8989999890327454\n",
      "Batch: 83  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 84  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 85  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 86  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 87  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 88  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 89  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 90  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 91  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 92  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 93  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 94  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 95  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 96  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 97  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 98  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 99  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 100  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 101  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 102  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 103  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 104  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 105  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 106  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 107  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 108  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 109  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 110  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 111  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9010000228881836\n",
      "Batch: 112  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9010000228881836\n",
      "Batch: 113  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 114  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 115  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 116  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 117  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.8840000033378601\n",
      "Batch: 118  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.8999999761581421\n",
      "Batch: 119  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9150000214576721\n",
      "Batch: 120  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 121  Training Accuracy: 0.8399999737739563\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 122  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 123  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 124  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 125  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 126  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 127  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8830000162124634\n",
      "Batch: 128  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.8920000195503235\n",
      "Batch: 129  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9039999842643738\n",
      "Batch: 130  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 131  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9049999713897705\n",
      "Batch: 132  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 133  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 134  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 135  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 136  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 137  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 138  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 139  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 140  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 141  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 142  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 143  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 144  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 145  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 146  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 147  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 148  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 149  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 150  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 151  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 152  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9120000004768372\n",
      "Batch: 153  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 154  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 155  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 156  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9010000228881836\n",
      "Batch: 157  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.8970000147819519\n",
      "Batch: 158  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 159  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 160  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 161  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 162  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9169999957084656\n",
      "Batch: 163  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 164  Training Accuracy: 0.8500000238418579\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 165  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 166  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 167  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 168  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 169  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 170  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 171  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 172  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 173  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 174  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 175  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 176  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 177  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 178  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 179  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 180  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 181  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 182  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 183  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 184  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 185  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 186  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 187  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 188  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 189  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 190  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 191  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 192  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 193  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.902999997138977\n",
      "Batch: 194  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 195  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 196  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 197  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 198  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 199  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 200  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 201  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 202  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 203  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 204  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 205  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 206  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9139999747276306\n",
      "Batch: 207  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 208  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 209  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 210  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 211  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 212  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 213  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 214  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 215  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 216  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 217  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 218  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 219  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 220  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 221  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.875\n",
      "Batch: 222  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 223  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 224  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 225  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 226  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 227  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 228  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 229  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 230  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 231  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 232  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 233  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 234  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 235  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9150000214576721\n",
      "Batch: 236  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.8790000081062317\n",
      "Batch: 237  Training Accuracy: 0.8299999833106995\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 238  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 239  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 240  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 241  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 242  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 243  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 244  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 245  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 246  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 247  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 248  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 249  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 250  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 251  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 252  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 253  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 254  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 255  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 256  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 257  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 258  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 259  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9129999876022339\n",
      "Batch: 260  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 261  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 262  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 263  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 264  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 265  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 266  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 267  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 268  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 269  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 270  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 271  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 272  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 273  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 274  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 275  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 276  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 277  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 278  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 279  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 280  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 281  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 282  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 283  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 284  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 285  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 286  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 287  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 288  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 289  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 290  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 291  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 292  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 293  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 294  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 295  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 296  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 297  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 298  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 299  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 300  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 301  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 302  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 303  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 304  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 305  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 306  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 307  Training Accuracy: 0.8600000143051147\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 308  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 309  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 310  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 311  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 312  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 313  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 314  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 315  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 316  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 317  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 318  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 319  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 320  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 321  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 322  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 323  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 324  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 325  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 326  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 327  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 328  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 329  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 330  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 331  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 332  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 333  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 334  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 335  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 336  Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 337  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 338  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 339  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 340  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 341  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 342  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 343  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 344  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 345  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 346  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 347  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 348  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 349  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 350  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 351  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 352  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 353  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 354  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 355  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 356  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 357  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 358  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 359  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 360  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 361  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 362  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 363  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 364  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 365  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 366  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 367  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 368  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 369  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 370  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 371  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 372  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 373  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 374  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 375  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 376  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 377  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9210000038146973\n",
      "Batch: 378  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 379  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 380  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 381  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 382  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 383  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 384  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 385  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 386  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 387  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 388  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 389  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 390  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 391  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 392  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 393  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 394  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 395  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 396  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 397  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 398  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 399  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 400  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 401  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 402  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 403  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 404  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 405  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 406  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 407  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 408  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 409  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 410  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 411  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 412  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 413  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 414  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 415  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 416  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 417  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 418  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 419  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 420  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 421  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 422  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.906000018119812\n",
      "Batch: 423  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 424  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 425  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 426  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 427  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 428  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 429  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 430  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 431  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 432  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 433  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 434  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 435  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 436  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 437  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 438  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 439  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 440  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 441  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 442  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 443  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 444  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 445  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 446  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 447  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 448  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 449  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 450  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 451  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 452  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 453  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 454  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 455  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 456  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 457  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 458  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 459  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 460  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 461  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 462  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 463  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 464  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 465  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 466  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 467  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 468  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 469  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 470  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 471  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 472  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 473  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 474  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 475  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 476  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 477  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 478  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 479  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 480  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 481  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 482  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 483  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 484  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 485  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 486  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 487  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 488  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 489  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 490  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 491  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 492  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 493  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 494  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 495  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 496  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 497  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 498  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 499  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 500  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 501  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 502  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 503  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 504  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 505  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 506  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 507  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 508  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 509  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 510  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 511  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 512  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 513  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 514  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 515  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 516  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 517  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 518  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 519  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 520  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 521  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 522  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 523  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 524  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 525  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 526  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 527  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 528  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 529  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 530  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 531  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 532  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 533  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 534  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 535  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 536  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 537  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 538  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 539  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 540  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 541  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 542  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 543  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 544  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 545  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 546  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 547  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 548  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 549  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 550  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 551  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 552  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 553  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 554  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 555  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 556  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 557  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 558  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 559  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 560  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 561  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 562  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9070000052452087\n",
      "Batch: 563  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 564  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 565  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 566  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 567  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 568  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 569  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 570  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 571  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 572  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 573  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 574  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 575  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 576  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 577  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 578  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 579  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 580  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 581  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 582  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 583  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 584  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9290000200271606\n",
      "Batch: 585  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 586  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 587  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 588  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 589  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 590  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 591  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 592  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 593  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 594  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 595  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 596  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 597  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 598  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 599  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "\n",
      "\n",
      "Epoch 1 \n",
      "\n",
      "\n",
      "Batch: 0  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 1  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 2  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 3  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 4  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 5  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 6  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 7  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 8  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 9  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 10  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 11  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 12  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 13  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 14  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 15  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 16  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 17  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 18  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 19  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 20  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 21  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 22  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 23  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9629999995231628\n",
      "Batch: 24  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 25  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 26  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 27  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 28  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 29  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 30  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 31  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 32  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 33  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 34  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 35  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 36  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 37  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 38  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 39  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 40  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 41  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 42  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 43  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 44  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 45  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 46  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 47  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 48  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 49  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 50  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 51  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.906000018119812\n",
      "Batch: 52  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9269999861717224\n",
      "Batch: 53  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 54  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 55  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 56  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 57  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 58  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 59  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 60  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 61  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 62  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 63  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 64  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 65  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 66  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 67  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 68  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 69  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 70  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 71  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 72  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9300000071525574\n",
      "Batch: 73  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 74  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 75  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 76  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 77  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 78  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 79  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 80  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 81  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 82  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 83  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 84  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 85  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 86  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 87  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 88  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 89  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 90  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 91  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 92  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 93  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 94  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 95  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 96  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 97  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 98  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 99  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 100  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 101  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 102  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 103  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 104  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 105  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 106  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 107  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 108  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 109  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 110  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 111  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 112  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 113  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 114  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 115  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 116  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 117  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 118  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 119  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 120  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 121  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 122  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 123  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 124  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 125  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 126  Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 127  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 128  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 129  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 130  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 131  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 132  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 133  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 134  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 135  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 136  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 137  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 138  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 139  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 140  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 141  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 142  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 143  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 144  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 145  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 146  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 147  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 148  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 149  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 150  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 151  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 152  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 153  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 154  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 155  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 156  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 157  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 158  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 159  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 160  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 161  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 162  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 163  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 164  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 165  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 166  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 167  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 168  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9229999780654907\n",
      "Batch: 169  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 170  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 171  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 172  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 173  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 174  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 175  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 176  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 177  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 178  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 179  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 180  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 181  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 182  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 183  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 184  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 185  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 186  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 187  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 188  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 189  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 190  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 191  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 192  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 193  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 194  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 195  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 196  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 197  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 198  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 199  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 200  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 201  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 202  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 203  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 204  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 205  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 206  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 207  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 208  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 209  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 210  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 211  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 212  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 213  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 214  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 215  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 216  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 217  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 218  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 219  Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 220  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 221  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 222  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 223  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 224  Training Accuracy: 0.8799999952316284\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 225  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 226  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 227  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 228  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 229  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 230  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 231  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 232  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 233  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 234  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 235  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 236  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 237  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 238  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 239  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 240  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 241  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 242  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 243  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 244  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 245  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 246  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 247  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 248  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 249  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 250  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 251  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 252  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 253  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 254  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 255  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 256  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 257  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 258  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 259  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 260  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 261  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 262  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 263  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 264  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 265  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9190000295639038\n",
      "Batch: 266  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9240000247955322\n",
      "Batch: 267  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 268  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 269  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 270  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 271  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 272  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 273  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 274  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 275  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 276  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 277  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 278  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9179999828338623\n",
      "Batch: 279  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 280  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 281  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 282  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 283  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 284  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 285  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 286  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 287  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 288  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 289  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 290  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 291  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 292  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 293  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 294  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 295  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 296  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 297  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 298  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 299  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9639999866485596\n",
      "Batch: 300  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9649999737739563\n",
      "Batch: 301  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 302  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 303  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 304  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 305  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 306  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 307  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 308  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 309  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 310  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 311  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 312  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 313  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 314  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 315  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 316  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 317  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 318  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 319  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 320  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 321  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 322  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 323  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 324  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 325  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 326  Training Accuracy: 0.8899999856948853\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 327  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9200000166893005\n",
      "Batch: 328  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 329  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 330  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 331  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 332  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 333  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 334  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 335  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 336  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 337  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 338  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 339  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 340  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 341  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 342  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 343  Training Accuracy: 0.8700000047683716\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 344  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 345  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 346  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 347  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 348  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 349  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 350  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 351  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 352  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 353  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 354  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 355  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 356  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 357  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 358  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 359  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9419999718666077\n",
      "Batch: 360  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 361  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 362  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 363  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 364  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 365  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 366  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.925000011920929\n",
      "Batch: 367  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 368  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 369  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9049999713897705\n",
      "Batch: 370  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 371  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9259999990463257\n",
      "Batch: 372  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 373  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 374  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 375  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 376  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 377  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 378  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 379  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 380  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 381  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 382  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 383  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 384  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 385  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 386  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 387  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 388  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 389  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 390  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 391  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 392  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9309999942779541\n",
      "Batch: 393  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9390000104904175\n",
      "Batch: 394  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 395  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 396  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 397  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 398  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 399  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 400  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 401  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 402  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 403  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 404  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 405  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 406  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 407  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 408  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 409  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 410  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 411  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 412  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 413  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 414  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 415  Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 416  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 417  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 418  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 419  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 420  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 421  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 422  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 423  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 424  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 425  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9330000281333923\n",
      "Batch: 426  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 427  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 428  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 429  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 430  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 431  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 432  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 433  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 434  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 435  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 436  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 437  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 438  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 439  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 440  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 441  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 442  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9629999995231628\n",
      "Batch: 443  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9639999866485596\n",
      "Batch: 444  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9639999866485596\n",
      "Batch: 445  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 446  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 447  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 448  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9629999995231628\n",
      "Batch: 449  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 450  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9710000157356262\n",
      "Batch: 451  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9670000076293945\n",
      "Batch: 452  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9710000157356262\n",
      "Batch: 453  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9700000286102295\n",
      "Batch: 454  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9700000286102295\n",
      "Batch: 455  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9679999947547913\n",
      "Batch: 456  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9670000076293945\n",
      "Batch: 457  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 458  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 459  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 460  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 461  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 462  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9279999732971191\n",
      "Batch: 463  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 464  Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 465  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 466  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 467  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 468  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 469  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 470  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 471  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9350000023841858\n",
      "Batch: 472  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 473  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 474  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 475  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 476  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 477  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 478  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 479  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 480  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 481  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 482  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 483  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 484  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 485  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 486  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 487  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 488  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 489  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 490  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 491  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 492  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 493  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 494  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 495  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 496  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 497  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 498  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 499  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 500  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 501  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 502  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 503  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 504  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 505  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9359999895095825\n",
      "Batch: 506  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9409999847412109\n",
      "Batch: 507  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 508  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 509  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 510  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 511  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 512  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 513  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 514  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 515  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 516  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 517  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 518  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 519  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 520  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 521  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 522  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 523  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 524  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 525  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 526  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 527  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 528  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 529  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 530  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 531  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 532  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 533  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 534  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.8790000081062317\n",
      "Batch: 535  Training Accuracy: 0.8399999737739563\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 536  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 537  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 538  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 539  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 540  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 541  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9629999995231628\n",
      "Batch: 542  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9629999995231628\n",
      "Batch: 543  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 544  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 545  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 546  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 547  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 548  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9459999799728394\n",
      "Batch: 549  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 550  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 551  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 552  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 553  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 554  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 555  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 556  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 557  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 558  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9639999866485596\n",
      "Batch: 559  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9610000252723694\n",
      "Batch: 560  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 561  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 562  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 563  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 564  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 565  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9629999995231628\n",
      "Batch: 566  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 567  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 568  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 569  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 570  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 571  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 572  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 573  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 574  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9430000185966492\n",
      "Batch: 575  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 576  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 577  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 578  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9589999914169312\n",
      "Batch: 579  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 580  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 581  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 582  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9380000233650208\n",
      "Batch: 583  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 584  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9340000152587891\n",
      "Batch: 585  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 586  Training Accuracy: 0.8999999761581421\n",
      "Testing Accuracy: 0.9480000138282776\n",
      "Batch: 587  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 588  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 589  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 590  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 591  Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 592  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 593  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 594  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 595  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9509999752044678\n",
      "Batch: 596  Training Accuracy: 0.9100000262260437\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 597  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 598  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 599  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.949999988079071\n",
      "\n",
      "\n",
      "Epoch 2 \n",
      "\n",
      "\n",
      "Batch: 0  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9440000057220459\n",
      "Batch: 1  Training Accuracy: 0.9200000166893005\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 2  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 3  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 4  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 5  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9369999766349792\n",
      "Batch: 6  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9319999814033508\n",
      "Batch: 7  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9399999976158142\n",
      "Batch: 8  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 9  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 10  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 11  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 12  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 13  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 14  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 15  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 16  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 17  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 18  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 19  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 20  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 21  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 22  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 23  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 24  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 25  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 26  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 27  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 28  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 29  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 30  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 31  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9449999928474426\n",
      "Batch: 32  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 33  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 34  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.949999988079071\n",
      "Batch: 35  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 36  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 37  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 38  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9580000042915344\n",
      "Batch: 39  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 40  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9470000267028809\n",
      "Batch: 41  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 42  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 43  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 44  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 45  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 46  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 47  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 48  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 49  Training Accuracy: 0.9399999976158142\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 50  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 51  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 52  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 53  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9559999704360962\n",
      "Batch: 54  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 55  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.9549999833106995\n",
      "Batch: 56  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 57  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9620000123977661\n",
      "Batch: 58  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9599999785423279\n",
      "Batch: 59  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 60  Training Accuracy: 0.9900000095367432\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 61  Training Accuracy: 0.9599999785423279\n",
      "Testing Accuracy: 0.9490000009536743\n",
      "Batch: 62  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9520000219345093\n",
      "Batch: 63  Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.953000009059906\n",
      "Batch: 64  Training Accuracy: 0.9700000286102295\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 65  Training Accuracy: 0.9300000071525574\n",
      "Testing Accuracy: 0.9539999961853027\n",
      "Batch: 66  Training Accuracy: 0.949999988079071\n",
      "Testing Accuracy: 0.9570000171661377\n",
      "Batch: 67  Training Accuracy: 0.9800000190734863\n",
      "Testing Accuracy: 0.9589999914169312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((batch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m50\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     acc_batch_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((torch\u001b[38;5;241m.\u001b[39margmax(y_pred,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m-\u001b[39my) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y)\n\u001b[0;32m---> 18\u001b[0m     y_test_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(X_test_gpu[:\u001b[38;5;241m1000\u001b[39m])\n\u001b[1;32m     20\u001b[0m     acc_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((torch\u001b[38;5;241m.\u001b[39margmax(y_test_pred,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m-\u001b[39my_test_gpu[:\u001b[38;5;241m1000\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch:\u001b[39m\u001b[38;5;124m'\u001b[39m,batch,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Training Accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, acc_batch_train\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m, in \u001b[0;36mmodel_linear.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,X):\n\u001b[0;32m---> 18\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmain(X)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adadelta(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        #print(f'Batch {batch}, Loss {loss}')\n",
    "        opt.zero_grad()\n",
    "        y_pred = model.forward(X)\n",
    "        loss = criterion(y_pred,y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        if ((batch%50) == 0) or True:\n",
    "            acc_batch_train = sum((torch.argmax(y_pred,dim=1)-y) == 0)/len(y)\n",
    "            y_test_pred = model.forward(X_test_gpu[:1000])\n",
    "\n",
    "            acc_test = sum((torch.argmax(y_test_pred,dim=1)-y_test_gpu[:1000]) == 0)/1000\n",
    "\n",
    "            print('Batch:',batch,' Training Accuracy:', acc_batch_train.item())\n",
    "            print('Testing Accuracy:',acc_test.item())\n",
    "            train_acc_list.append(acc_batch_train.item())\n",
    "            test_acc_list.append(acc_test.item())\n",
    "    \n",
    "    print(f'\\n\\nEpoch {epoch} \\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ea3948d-af8a-4680-a84c-6ed41ebd0011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is: tensor(0.9630)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.forward(X_test_gpu)\n",
    "acc_test = sum((torch.argmax(y_test_pred,dim=1)-y_test_gpu) == 0)/10000\n",
    "print('Test accuracy is:',acc_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25fb60-7a6a-4842-8c21-bd191d246418",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c55af465-943f-4d3f-a47a-bb597d787cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the dataset\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False)\n",
    "\n",
    "X = trainset.data\n",
    "y = trainset.targets\n",
    "X = X.type(torch.float)\n",
    "X = (X/255)\n",
    "\n",
    "X_test = testset.data\n",
    "y_test = testset.targets\n",
    "X_test = X_test.type(torch.float)\n",
    "X_test = (X_test/255)\n",
    "\n",
    "\n",
    "# Preprocessing/Transforming\n",
    "# Define a series of transformations\n",
    "transform = transforms.Compose([\n",
    "    #transforms.RandomRotation(20),\n",
    "    #transforms.Lambda(lambda x: x.view(x.size(0), -1)) # Flatten the tensor\n",
    "])\n",
    "\n",
    "X_t = transform(X)\n",
    "y_t = y\n",
    "\n",
    "\n",
    "X_test = transform(X_test)\n",
    "X_test_gpu = X_test.to(device)\n",
    "y_test_gpu = y_test.to(device)\n",
    "\n",
    "\n",
    "X_gpu = X_t.to(device)\n",
    "y_gpu = y.to(device)\n",
    "# Convert to Dataset and put in a DataLoader\n",
    "tensor_dataset = TensorDataset(X_gpu, y_gpu)\n",
    "dataloader = DataLoader(tensor_dataset,batch_size=100,shuffle = True)\n",
    "\n",
    "\n",
    "tensor_dataset_test = TensorDataset(X_test, y_test)\n",
    "dataloader_test = DataLoader(tensor_dataset_test,batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1487a34d-913d-4ce3-93db-f8ef41362032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "class Conv_Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels = 1,out_channels = 6,kernel_size = (3,3),stride = 1,padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            torch.nn.Conv2d(in_channels = 6,out_channels = 16,kernel_size = (5,5),stride = 1,padding = 0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool2d(kernel_size = 2,stride = 2),\n",
    "            torch.nn.Flatten(start_dim = 1),\n",
    "            torch.nn.Linear(49*16,120),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(120,84),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(84,10),\n",
    "            torch.nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "        y_pred = self.main(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71c8cc39-9152-4896-bd7a-ceab0d82e449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate your model and transfer it to GPU (if available)\n",
    "model = Conv_Network().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e851a660-a29c-4c98-8234-d088e5012eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [6, 1, 3, 3], expected input[1, 100, 28, 28] to have 1 channels, but got 100 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, (X,y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#print(f'Batch {batch}, Loss {loss}')\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(X)\n\u001b[1;32m     12\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(y_pred,y)\n\u001b[1;32m     13\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[0;32mIn[21], line 24\u001b[0m, in \u001b[0;36mConv_Network.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,X):\n\u001b[0;32m---> 24\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmain(X)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 1, 3, 3], expected input[1, 100, 28, 28] to have 1 channels, but got 100 channels instead"
     ]
    }
   ],
   "source": [
    "opt = torch.optim.Adadelta(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        #print(f'Batch {batch}, Loss {loss}')\n",
    "        opt.zero_grad()\n",
    "        y_pred = model.forward(X)\n",
    "        loss = criterion(y_pred,y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        if ((batch%50) == 0) or True:\n",
    "            acc_batch_train = sum((torch.argmax(y_pred,dim=1)-y) == 0)/len(y)\n",
    "            y_test_pred = model.forward(X_test_gpu[:1000])\n",
    "\n",
    "            acc_test = sum((torch.argmax(y_test_pred,dim=1)-y_test_gpu[:1000]) == 0)/1000\n",
    "\n",
    "            print('Batch:',batch,' Training Accuracy:', acc_batch_train.item())\n",
    "            print('Testing Accuracy:',acc_test.item())\n",
    "            train_acc_list.append(acc_batch_train.item())\n",
    "            test_acc_list.append(acc_test.item())\n",
    "    \n",
    "    print(f'\\n\\nEpoch {epoch} \\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0d657-0339-48d8-b7fe-c60ea4c84ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "img = dataloader.dataset.tensors[0][2].view(28,28)\n",
    "plt.imshow(img, cmap='gray')  # Use the 'gray' colormap for grayscale images\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
