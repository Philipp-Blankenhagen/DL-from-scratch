{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0abdc1bb-01e2-464d-bee9-809db759593e",
      "metadata": {
        "tags": [],
        "id": "0abdc1bb-01e2-464d-bee9-809db759593e"
      },
      "outputs": [],
      "source": [
        "import torch, torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "773a326e-0567-49cb-977d-236415ab070a",
      "metadata": {
        "tags": [],
        "id": "773a326e-0567-49cb-977d-236415ab070a",
        "outputId": "d872eb09-4d8c-4c73-e1f5-6594ed869cb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9545508d-f3de-4755-b41c-81f6ace24452",
      "metadata": {
        "id": "9545508d-f3de-4755-b41c-81f6ace24452"
      },
      "source": [
        "# MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "5gjsN823FIrC"
      },
      "id": "5gjsN823FIrC"
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].shape"
      ],
      "metadata": {
        "id": "KYk2ULfwFG_N",
        "outputId": "23e5ee87-751a-4a9d-f621-da1cbab4759c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "KYk2ULfwFG_N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4Yi0-EApFMI5"
      },
      "id": "4Yi0-EApFMI5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test End"
      ],
      "metadata": {
        "id": "_yid5E5cFHoX"
      },
      "id": "_yid5E5cFHoX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b9b9429-0e92-4230-b1a8-f6e15b54c051",
      "metadata": {
        "tags": [],
        "id": "2b9b9429-0e92-4230-b1a8-f6e15b54c051"
      },
      "outputs": [],
      "source": [
        "# Getting the dataset\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True)\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False)\n",
        "\n",
        "X = trainset.data\n",
        "y = trainset.targets\n",
        "X = X.type(torch.float)\n",
        "X = (X/255)\n",
        "\n",
        "X_test = testset.data\n",
        "y_test = testset.targets\n",
        "X_test = X_test.type(torch.float)\n",
        "X_test = (X_test/255)\n",
        "\n",
        "\n",
        "# Preprocessing/Transforming\n",
        "# Define a series of transformations\n",
        "transform = transforms.Compose([\n",
        "    #transforms.RandomRotation(20),\n",
        "    transforms.Lambda(lambda x: x.view(x.size(0), -1)) # Flatten the tensor\n",
        "])\n",
        "\n",
        "X_t = transform(X)\n",
        "y_t = y\n",
        "\n",
        "\n",
        "X_test = transform(X_test)\n",
        "X_test_gpu = X_test.to(device)\n",
        "y_test_gpu = y_test.to(device)\n",
        "\n",
        "\n",
        "X_gpu = X_t.to(device)\n",
        "y_gpu = y.to(device)\n",
        "# Convert to Dataset and put in a DataLoader\n",
        "tensor_dataset = TensorDataset(X_gpu, y_gpu)\n",
        "dataloader = DataLoader(tensor_dataset,batch_size=1,shuffle = True)\n",
        "\n",
        "\n",
        "tensor_dataset_test = TensorDataset(X_test, y_test)\n",
        "dataloader_test = DataLoader(tensor_dataset_test,batch_size=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Linear Layer\n",
        "class CustomLinearLayer(torch.nn.Module):\n",
        "    def __init__(self, input_size, output_size,bias=True):\n",
        "        super(CustomLinearLayer, self).__init__()\n",
        "\n",
        "        self.weight = nn.Parameter(torch.Tensor(output_size,input_size))\n",
        "        if bias:\n",
        "          self.bias = nn.Parameter(torch.Tensor(output_size))\n",
        "\n",
        "        #nn.init.kaiming_uniform_(self.weight.data, a=0, mode='fan_in', nonlinearity='relu') # kaiming He weight initialization\n",
        "        #nn.init.kaiming_uniform_(self.bias.data, a=0, mode='fan_in', nonlinearity='relu')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Define parameters (weights and bias)\n",
        "        if False:\n",
        "          stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "          self.weight.uniform_(-stdv, stdv)\n",
        "          if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Implement the forward pass\n",
        "        #print(x.shape)\n",
        "        #x = torch.matmul(x, self.weight.T)\n",
        "        x = x@self.weight.T + self.bias\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "lk7cz8416p39"
      },
      "id": "lk7cz8416p39",
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "id": "5919e36a-cff4-4401-be3d-9e540e7a34f2",
      "metadata": {
        "tags": [],
        "id": "5919e36a-cff4-4401-be3d-9e540e7a34f2"
      },
      "outputs": [],
      "source": [
        "class model_linear(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = torch.nn.Sequential(\n",
        "            torch.nn.Linear(784, 3000,bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(3000, 3000,bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(3000, 1000,bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(1000, 500,bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(500,10,bias=True),\n",
        "            torch.nn.Softmax(dim =1)\n",
        "        )\n",
        "\n",
        "    def forward(self,X):\n",
        "        y_pred = self.main(X)\n",
        "        return y_pred\n",
        "\n",
        "    def predict(self,X):\n",
        "        with torch.no_grad():\n",
        "            y_pred = self.main(X)\n",
        "            y_class = torch.argmax(y_pred,dim=1)\n",
        "        return y_class"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class model_custom_linear(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = torch.nn.Sequential(\n",
        "            CustomLinearLayer(784, 3000,bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            CustomLinearLayer(3000, 3000,bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            CustomLinearLayer(3000, 1000,bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            CustomLinearLayer(1000, 500,bias=True),\n",
        "            torch.nn.ReLU(),\n",
        "            CustomLinearLayer(500,10,bias=True),\n",
        "            torch.nn.Softmax(dim =1)\n",
        "        )\n",
        "\n",
        "    def forward(self,X):\n",
        "        y_pred = self.main(X)\n",
        "        return y_pred\n",
        "\n",
        "    def predict(self,X):\n",
        "        with torch.no_grad():\n",
        "            y_pred = self.main(X)\n",
        "            y_class = torch.argmax(y_pred,dim=1)\n",
        "        return y_class"
      ],
      "metadata": {
        "id": "nb54hkeX84Ou"
      },
      "id": "nb54hkeX84Ou",
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "id": "71c6ceab-88b4-456d-9630-10bf2615569d",
      "metadata": {
        "tags": [],
        "id": "71c6ceab-88b4-456d-9630-10bf2615569d",
        "outputId": "6e4529f0-9732-43af-fe85-dc5f1d651d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Fan in and fan out can not be computed for tensor with fewer than 2 dimensions",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-218-c26ccc01c8bd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instantiate your model and transfer it to GPU (if available)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#model = model_linear().to(device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_custom_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-217-afa8bd4a01f9>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         self.main = torch.nn.Sequential(\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mCustomLinearLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mCustomLinearLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-215-b80601ec51e6>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, output_size, bias)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fan_in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkaiming_uniform_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fan_in'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnonlinearity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36mkaiming_uniform_\u001b[0;34m(tensor, a, mode, nonlinearity, generator)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializing zero-element tensors is a no-op\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mfan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_correct_fan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_gain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonlinearity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36m_calculate_correct_fan\u001b[0;34m(tensor, mode)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mode {mode} not supported, please use one of {valid_modes}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m     \u001b[0mfan_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfan_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_fan_in_and_fan_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfan_in\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fan_in'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfan_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/init.py\u001b[0m in \u001b[0;36m_calculate_fan_in_and_fan_out\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0mdimensions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdimensions\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Fan in and fan out can not be computed for tensor with fewer than 2 dimensions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mnum_input_fmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Fan in and fan out can not be computed for tensor with fewer than 2 dimensions"
          ]
        }
      ],
      "source": [
        "# Instantiate your model and transfer it to GPU (if available)\n",
        "#model = model_linear().to(device)\n",
        "model = model_custom_linear().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d8fc62a-125b-4da9-a138-6358af0c51d6",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "collapsed": true,
        "id": "5d8fc62a-125b-4da9-a138-6358af0c51d6",
        "outputId": "3bc0c5b3-c5c2-43e3-fdd9-b7aeab4d8558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch: 0  Training Accuracy: 0.0\n",
            "Testing Accuracy: 0.11400000751018524\n",
            "Batch: 500  Training Accuracy: 0.0\n",
            "Testing Accuracy: 0.11400000751018524\n",
            "Batch: 1000  Training Accuracy: 0.0\n",
            "Testing Accuracy: 0.11400000751018524\n",
            "Batch: 1500  Training Accuracy: 0.0\n",
            "Testing Accuracy: 0.11400000751018524\n",
            "Batch: 2000  Training Accuracy: 0.0\n",
            "Testing Accuracy: 0.11400000751018524\n",
            "Batch: 2500  Training Accuracy: 0.0\n",
            "Testing Accuracy: 0.11400000751018524\n",
            "Batch: 3000  Training Accuracy: 0.0\n",
            "Testing Accuracy: 0.11400000751018524\n",
            "Batch: 3500  Training Accuracy: 0.0\n",
            "Testing Accuracy: 0.11400000751018524\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-212-fa71efb883b9>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0;31m#print('\\nGradient',param.grad.data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "opt = torch.optim.Adadelta(model.parameters())\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "for epoch in range(2):\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "        #print(f'Batch {batch}, Loss {loss}')\n",
        "        opt.zero_grad()\n",
        "        y_pred = model.forward(X)\n",
        "        loss = criterion(y_pred,y)\n",
        "        loss.backward()\n",
        "        for param in model.parameters():\n",
        "          #print('\\nGradient',param.grad.data)\n",
        "          1+1\n",
        "\n",
        "        opt.step()\n",
        "\n",
        "        if ((batch%500) == 0) or False:\n",
        "            acc_batch_train = sum((torch.argmax(y_pred,dim=1)-y) == 0)/len(y)\n",
        "            y_test_pred = model.forward(X_test_gpu[:1000])\n",
        "\n",
        "            acc_test = sum((torch.argmax(y_test_pred,dim=1)-y_test_gpu[:1000]) == 0)/1000\n",
        "\n",
        "            print('Batch:',batch,' Training Accuracy:', acc_batch_train.item())\n",
        "            print('Testing Accuracy:',acc_test.item())\n",
        "            train_acc_list.append(acc_batch_train.item())\n",
        "            test_acc_list.append(acc_test.item())\n",
        "\n",
        "    print(f'\\n\\nEpoch {epoch} \\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ea3948d-af8a-4680-a84c-6ed41ebd0011",
      "metadata": {
        "id": "5ea3948d-af8a-4680-a84c-6ed41ebd0011",
        "outputId": "f58de124-198c-49fe-a2c4-0636be2e707f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy is: tensor(0.9681, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "y_test_pred = model.forward(X_test_gpu)\n",
        "acc_test = sum((torch.argmax(y_test_pred,dim=1)-y_test_gpu) == 0)/10000\n",
        "print('Test accuracy is:',acc_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e25fb60-7a6a-4842-8c21-bd191d246418",
      "metadata": {
        "tags": [],
        "id": "4e25fb60-7a6a-4842-8c21-bd191d246418"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c55af465-943f-4d3f-a47a-bb597d787cfc",
      "metadata": {
        "tags": [],
        "id": "c55af465-943f-4d3f-a47a-bb597d787cfc"
      },
      "outputs": [],
      "source": [
        "# Getting the dataset\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True)\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False)\n",
        "\n",
        "X = trainset.data\n",
        "y = trainset.targets\n",
        "X = X.type(torch.float)\n",
        "X = (X/255)\n",
        "\n",
        "X_test = testset.data\n",
        "y_test = testset.targets\n",
        "X_test = X_test.type(torch.float)\n",
        "X_test = (X_test/255)\n",
        "\n",
        "\n",
        "# Preprocessing/Transforming\n",
        "# Define a series of transformations\n",
        "transform = transforms.Compose([\n",
        "    #transforms.RandomRotation(20),\n",
        "    #transforms.Lambda(lambda x: x.view(x.size(0), -1)) # Flatten the tensor\n",
        "])\n",
        "\n",
        "X_t = transform(X)\n",
        "y_t = y\n",
        "\n",
        "\n",
        "X_test = transform(X_test)\n",
        "X_test_gpu = X_test.to(device)\n",
        "y_test_gpu = y_test.to(device)\n",
        "\n",
        "\n",
        "X_gpu = X_t.to(device)\n",
        "y_gpu = y.to(device)\n",
        "# Convert to Dataset and put in a DataLoader\n",
        "tensor_dataset = TensorDataset(X_gpu, y_gpu)\n",
        "dataloader = DataLoader(tensor_dataset,batch_size=100,shuffle = True)\n",
        "\n",
        "\n",
        "tensor_dataset_test = TensorDataset(X_test, y_test)\n",
        "dataloader_test = DataLoader(tensor_dataset_test,batch_size=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1487a34d-913d-4ce3-93db-f8ef41362032",
      "metadata": {
        "tags": [],
        "id": "1487a34d-913d-4ce3-93db-f8ef41362032"
      },
      "outputs": [],
      "source": [
        "# Convolutional Neural Network\n",
        "\n",
        "class Conv_Network(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(in_channels = 1,out_channels = 6,kernel_size = (3,3),stride = 1,padding = 1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
        "            torch.nn.Conv2d(in_channels = 6,out_channels = 16,kernel_size = (5,5),stride = 1,padding = 0),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.AvgPool2d(kernel_size = 2,stride = 2),\n",
        "            torch.nn.Flatten(start_dim = 1),\n",
        "            torch.nn.Linear(49*16,120),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(120,84),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(84,10),\n",
        "            torch.nn.Softmax(dim = 1)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self,X):\n",
        "        y_pred = self.main(X)\n",
        "        return y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c8cc39-9152-4896-bd7a-ceab0d82e449",
      "metadata": {
        "id": "71c8cc39-9152-4896-bd7a-ceab0d82e449"
      },
      "outputs": [],
      "source": [
        "# Instantiate your model and transfer it to GPU (if available)\n",
        "model = Conv_Network().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e851a660-a29c-4c98-8234-d088e5012eda",
      "metadata": {
        "tags": [],
        "id": "e851a660-a29c-4c98-8234-d088e5012eda",
        "outputId": "3b80199e-c090-48df-e280-0e510f9b4bd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Given groups=1, weight of size [6, 1, 3, 3], expected input[1, 100, 28, 28] to have 1 channels, but got 100 channels instead",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5c4a74029128>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(f'Batch {batch}, Loss {loss}')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6a64a790fe8a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [6, 1, 3, 3], expected input[1, 100, 28, 28] to have 1 channels, but got 100 channels instead"
          ]
        }
      ],
      "source": [
        "opt = torch.optim.Adadelta(model.parameters())\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "train_acc_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "for epoch in range(5):\n",
        "    for batch, (X,y) in enumerate(dataloader):\n",
        "        #print(f'Batch {batch}, Loss {loss}')\n",
        "        opt.zero_grad()\n",
        "        y_pred = model.forward(X)\n",
        "        loss = criterion(y_pred,y)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        if ((batch%50) == 0) or True:\n",
        "            acc_batch_train = sum((torch.argmax(y_pred,dim=1)-y) == 0)/len(y)\n",
        "            y_test_pred = model.forward(X_test_gpu[:1000])\n",
        "\n",
        "            acc_test = sum((torch.argmax(y_test_pred,dim=1)-y_test_gpu[:1000]) == 0)/1000\n",
        "\n",
        "            print('Batch:',batch,' Training Accuracy:', acc_batch_train.item())\n",
        "            print('Testing Accuracy:',acc_test.item())\n",
        "            train_acc_list.append(acc_batch_train.item())\n",
        "            test_acc_list.append(acc_test.item())\n",
        "\n",
        "    print(f'\\n\\nEpoch {epoch} \\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bc0d657-0339-48d8-b7fe-c60ea4c84ba8",
      "metadata": {
        "tags": [],
        "id": "3bc0d657-0339-48d8-b7fe-c60ea4c84ba8"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "img = dataloader.dataset.tensors[0][2].view(28,28)\n",
        "plt.imshow(img, cmap='gray')  # Use the 'gray' colormap for grayscale images\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}