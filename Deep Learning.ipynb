{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4930b-2ca2-4582-a561-b6c2659522d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "git add .\n",
    "\n",
    "git remote add origin git@github.com:Philipp-Blankenhagen:DL-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0abdc1bb-01e2-464d-bee9-809db759593e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773a326e-0567-49cb-977d-236415ab070a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545508d-f3de-4755-b41c-81f6ace24452",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2b9b9429-0e92-4230-b1a8-f6e15b54c051",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the dataset\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False)\n",
    "\n",
    "X = trainset.data\n",
    "y = trainset.targets\n",
    "X = X.type(torch.float)\n",
    "X = (X/255)\n",
    "\n",
    "X_test = testset.data\n",
    "y_test = testset.targets\n",
    "X_test = X_test.type(torch.float)\n",
    "X_test = (X_test/255)\n",
    "\n",
    "\n",
    "# Preprocessing/Transforming\n",
    "# Define a series of transformations\n",
    "transform = transforms.Compose([\n",
    "    #transforms.RandomRotation(20),\n",
    "    transforms.Lambda(lambda x: x.view(x.size(0), -1)) # Flatten the tensor\n",
    "])\n",
    "\n",
    "X_t = transform(X)\n",
    "y_t = y\n",
    "\n",
    "\n",
    "X_test = transform(X_test)\n",
    "X_test_gpu = X_test.to(device)\n",
    "y_test_gpu = y_test.to(device)\n",
    "\n",
    "\n",
    "X_gpu = X_t.to(device)\n",
    "y_gpu = y.to(device)\n",
    "# Convert to Dataset and put in a DataLoader\n",
    "tensor_dataset = TensorDataset(X_gpu, y_gpu)\n",
    "dataloader = DataLoader(tensor_dataset,batch_size=100,shuffle = True)\n",
    "\n",
    "\n",
    "tensor_dataset_test = TensorDataset(X_test, y_test)\n",
    "dataloader_test = DataLoader(tensor_dataset_test,batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5919e36a-cff4-4401-be3d-9e540e7a34f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class model_linear(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = torch.nn.Sequential(\n",
    "            torch.nn.Linear(784, 5000,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(5000, 10000,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10000, 10000,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(10000, 5000,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(5000, 5000,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(5000, 5000,bias=True),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(5000,10,bias=True),\n",
    "            torch.nn.Softmax(dim =1)\n",
    "        )\n",
    "\n",
    "    def forward(self,X):\n",
    "        y_pred = self.main(X)\n",
    "        return y_pred\n",
    "    \n",
    "    def predict(self,X):\n",
    "        with torch.no_grad():\n",
    "            y_pred = self.main(X)\n",
    "            y_class = torch.argmax(y_pred,dim=1)\n",
    "        return y_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "71c6ceab-88b4-456d-9630-10bf2615569d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Instantiate your model and transfer it to GPU (if available)\n",
    "model = model_linear().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5d8fc62a-125b-4da9-a138-6358af0c51d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0  Training Accuracy: 0.07999999821186066\n",
      "Testing Accuracy: 0.11599999666213989\n",
      "Batch: 1  Training Accuracy: 0.15000000596046448\n",
      "Testing Accuracy: 0.11599999666213989\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred,y)\n\u001b[1;32m     13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 14\u001b[0m opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((batch\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m50\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     acc_batch_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m((torch\u001b[38;5;241m.\u001b[39margmax(y_pred,dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m-\u001b[39my) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adadelta.py:110\u001b[0m, in \u001b[0;36mAdadelta.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m     lr, rho, eps, weight_decay, foreach, maximize, differentiable \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     99\u001b[0m         group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    100\u001b[0m         group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrho\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m         group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    106\u001b[0m     )\n\u001b[1;32m    108\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(group, params_with_grad, grads, square_avgs, acc_deltas)\n\u001b[0;32m--> 110\u001b[0m     adadelta(\n\u001b[1;32m    111\u001b[0m         params_with_grad,\n\u001b[1;32m    112\u001b[0m         grads,\n\u001b[1;32m    113\u001b[0m         square_avgs,\n\u001b[1;32m    114\u001b[0m         acc_deltas,\n\u001b[1;32m    115\u001b[0m         lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    116\u001b[0m         rho\u001b[38;5;241m=\u001b[39mrho,\n\u001b[1;32m    117\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    118\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    119\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mforeach,\n\u001b[1;32m    120\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    121\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    122\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adadelta.py:211\u001b[0m, in \u001b[0;36madadelta\u001b[0;34m(params, grads, square_avgs, acc_deltas, foreach, differentiable, has_complex, lr, rho, eps, weight_decay, maximize)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adadelta\n\u001b[0;32m--> 211\u001b[0m func(\n\u001b[1;32m    212\u001b[0m     params,\n\u001b[1;32m    213\u001b[0m     grads,\n\u001b[1;32m    214\u001b[0m     square_avgs,\n\u001b[1;32m    215\u001b[0m     acc_deltas,\n\u001b[1;32m    216\u001b[0m     lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    217\u001b[0m     rho\u001b[38;5;241m=\u001b[39mrho,\n\u001b[1;32m    218\u001b[0m     eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    219\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    220\u001b[0m     maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    221\u001b[0m     differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    222\u001b[0m     has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    223\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/optim/adadelta.py:259\u001b[0m, in \u001b[0;36m_single_tensor_adadelta\u001b[0;34m(params, grads, square_avgs, acc_deltas, lr, rho, eps, weight_decay, maximize, differentiable, has_complex)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m differentiable:\n\u001b[1;32m    258\u001b[0m     delta \u001b[38;5;241m=\u001b[39m delta\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m--> 259\u001b[0m delta\u001b[38;5;241m.\u001b[39mdiv_(std)\u001b[38;5;241m.\u001b[39mmul_(grad)\n\u001b[1;32m    260\u001b[0m acc_delta\u001b[38;5;241m.\u001b[39mmul_(rho)\u001b[38;5;241m.\u001b[39maddcmul_(delta, delta, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m rho)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(param):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "opt = torch.optim.Adadelta(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        #print(f'Batch {batch}, Loss {loss}')\n",
    "        opt.zero_grad()\n",
    "        y_pred = model.forward(X)\n",
    "        loss = criterion(y_pred,y)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    \n",
    "        if ((batch%50) == 0) or True:\n",
    "            acc_batch_train = sum((torch.argmax(y_pred,dim=1)-y) == 0)/len(y)\n",
    "            y_test_pred = model.forward(X_test_gpu[:1000])\n",
    "\n",
    "            acc_test = sum((torch.argmax(y_test_pred,dim=1)-y_test_gpu[:1000]) == 0)/1000\n",
    "\n",
    "            print('Batch:',batch,' Training Accuracy:', acc_batch_train.item())\n",
    "            print('Testing Accuracy:',acc_test.item())\n",
    "            train_acc_list.append(acc_batch_train.item())\n",
    "            test_acc_list.append(acc_test.item())\n",
    "    \n",
    "    print(f'\\n\\nEpoch {epoch} \\n\\n')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25fb60-7a6a-4842-8c21-bd191d246418",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c55af465-943f-4d3f-a47a-bb597d787cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Getting the dataset\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True)\n",
    "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False)\n",
    "\n",
    "X = trainset.data\n",
    "y = trainset.targets\n",
    "X = X.type(torch.float)\n",
    "X = (X/255)\n",
    "\n",
    "X_test = testset.data\n",
    "y_test = testset.targets\n",
    "X_test = X_test.type(torch.float)\n",
    "X_test = (X_test/255)\n",
    "\n",
    "\n",
    "# Preprocessing/Transforming\n",
    "# Define a series of transformations\n",
    "transform = transforms.Compose([\n",
    "    #transforms.RandomRotation(20),\n",
    "    #transforms.Lambda(lambda x: x.view(x.size(0), -1)) # Flatten the tensor\n",
    "])\n",
    "\n",
    "X_t = transform(X)\n",
    "y_t = y\n",
    "\n",
    "\n",
    "X_test = transform(X_test)\n",
    "X_test_gpu = X_test.to(device)\n",
    "y_test_gpu = y_test.to(device)\n",
    "\n",
    "\n",
    "X_gpu = X_t.to(device)\n",
    "y_gpu = y.to(device)\n",
    "# Convert to Dataset and put in a DataLoader\n",
    "tensor_dataset = TensorDataset(X_gpu, y_gpu)\n",
    "dataloader = DataLoader(tensor_dataset,batch_size=100,shuffle = True)\n",
    "\n",
    "\n",
    "tensor_dataset_test = TensorDataset(X_test, y_test)\n",
    "dataloader_test = DataLoader(tensor_dataset_test,batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1487a34d-913d-4ce3-93db-f8ef41362032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "class Conv_Network(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.main = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels = 1,out_channels = 6,kernel_size = (3,3),stride = 1,padding = 1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size = 2, stride = 2),\n",
    "            torch.nn.Conv2d(in_channels = 6,out_channels = 16,kernel_size = (5,5),stride = 1,padding = 0),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.AvgPool2d(kernel_size = 2,stride = 2),\n",
    "            torch.nn.Flatten(start_dim = 1),\n",
    "            torch.nn.Linear(49*16,120),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(120,84),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(84,10),\n",
    "            torch.nn.Softmax(dim = 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,X):\n",
    "        y_pred = self.main(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baaaef0-5f9a-46e4-8c67-c4e0ca15df11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "e851a660-a29c-4c98-8234-d088e5012eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1761, 0.0026, 0.4907, 0.1703, 0.0032, 0.0173, 0.0153, 0.0007, 0.1165,\n",
       "        0.0074], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.forward(dataloader.dataset.tensors[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bc0d657-0339-48d8-b7fe-c60ea4c84ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "img = dataloader.dataset.tensors[0][2].view(28,28)\n",
    "plt.imshow(img, cmap='gray')  # Use the 'gray' colormap for grayscale images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e18414-d78e-4b95-b971-64f946ace21c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333b9711-ddd4-4a8b-ad94-82efd2140217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c8c2a-f74e-4e4a-913a-e1b611952d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
